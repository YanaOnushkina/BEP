{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Read Test Data\n",
      "Test data read --- 0.029819965362548828 seconds ---\n",
      "<numpy.lib.npyio.NpzFile object at 0x10d0ec750>\n",
      "Testing - Total examples per class [ 680. 1185.  478.  329.   74.  160.  161.]\n"
     ]
    }
   ],
   "source": [
    "def read_test_data(path):\n",
    "    start_time = time.time()\n",
    "    print(\"Start Read Test Data\")\n",
    "    data = np.load(path)\n",
    "    print(\"Test data read --- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(data)\n",
    "    X_train = data[\"X_test\"] # TODO\n",
    "    Y_train = data[\"Y_test\"]\n",
    "    print(\"Testing - Total examples per class\", np.sum(Y_train, axis=0))\n",
    "    return [X_train, Y_train]\n",
    "\n",
    "X_test, Y_test = read_test_data(\"/Users/blazejmanczak/Desktop/School/Year3/BEP/EvaluationRaf/testDataProcessedOriginal.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "senet = keras.models.load_model(\"/Users/blazejmanczak/Desktop/senetRafFromAcc64OrgDataAcc877\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = keras.models.load_model(\"/Users/blazejmanczak/Desktop/School/Year3/BEP/realTime/vggFaceAffectFullAdamFineTunedAcc64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3067/3067 [==============================] - 219s 71ms/sample - loss: 1.0595 - accuracy: 0.8063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0594631810072854, 0.8063254]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senet.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_vggface import utils\n",
    "\n",
    "def image_preprocessing(img):\n",
    "    pixels = img*255\n",
    "    #pixels = clahe((img*255).astype(np.uint8))\n",
    "    pixels_expanded = np.expand_dims(pixels.astype(np.float64), axis=0)\n",
    "    pre_pro = utils.preprocess_input(pixels_expanded, version=1)  # version 1 for VGG face\n",
    "    return pre_pro[0]/255\n",
    "\n",
    "\n",
    "datagenVal = ImageDataGenerator(\n",
    "        preprocessing_function = image_preprocessing,\n",
    "        dtype=\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "96/96 [==============================] - 310s 3s/step - loss: 0.6734 - accuracy: 0.8781\n",
      "[0.6734348892690226, 0.8780567]\n"
     ]
    }
   ],
   "source": [
    "evalDone = senet.evaluate(datagenVal.flow(X_test, Y_test))\n",
    "print(evalDone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsSenet = senet.predict(datagenVal.flow(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vggRaf = keras.models.load_model(\"/Users/blazejmanczak/Desktop/vggFaceFromAcc64OrgDataAcc853\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(vggRaf)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_tflite_vggRaf = converter.convert()\n",
    "f = open(\"vggRaf.tflite\", \"wb\")\n",
    "f.write(quantized_tflite_vggRaf)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(senet)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_tflite_senet = converter.convert()\n",
    "f = open(\"senetRight.tflite\", \"wb\")\n",
    "f.write(quantized_tflite_senet)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to evaluate the TF Lite model using \"validation\" dataset.\n",
    "# Referred from: https://www.tensorflow.org/lite/performance/post_training_integer_quant\n",
    "def evaluate_model(interpreter):\n",
    "    accurate_count = 0\n",
    "\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "    \n",
    "    print(input_index)\n",
    "    print(output_index)\n",
    "    # Run predictions on every image in the \"test\" dataset.\n",
    "    predictions = []\n",
    "    for val_image, val_label in zip(X_test[:5], Y_test[:5]):\n",
    "        val_image = image_preprocessing(val_image).astype(np.float32)\n",
    "        val_image = tf.expand_dims(val_image, 0) \n",
    "        print(val_image)\n",
    "        interpreter.set_tensor(input_index, val_image)\n",
    "\n",
    "        # Run inference.\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Post-processing: remove batch dimension and find the digit with highest\n",
    "        # probability.\n",
    "        probability = interpreter.get_tensor(output_index)\n",
    "        print(probability)\n",
    "        flower_id = np.argmax(probability[0])\n",
    "        print(flower_id)\n",
    "        predictions.append(flower_id)\n",
    "        val_label = np.argmax(val_label)\n",
    "        print(val_label)\n",
    "       \n",
    "        # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "        if flower_id == val_label:\n",
    "            #print(\"right\")\n",
    "            accurate_count += 1\n",
    "    \n",
    "    accuracy = accurate_count * 1.0 / len(predictions)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "0\n",
      "tf.Tensor(\n",
      "[[[[-0.3435059  -0.36377412 -0.46347567]\n",
      "   [-0.3552706  -0.3794604  -0.48308352]\n",
      "   [-0.3670353  -0.3912251  -0.49092665]\n",
      "   ...\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]]\n",
      "\n",
      "  [[-0.3435059  -0.3676957  -0.46739724]\n",
      "   [-0.3552706  -0.3794604  -0.47916195]\n",
      "   [-0.35919216 -0.38338196 -0.48308352]\n",
      "   ...\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]]\n",
      "\n",
      "  [[-0.34742746 -0.37161726 -0.4713188 ]\n",
      "   [-0.35134903 -0.37553883 -0.47524038]\n",
      "   [-0.34742746 -0.37161726 -0.4713188 ]\n",
      "   ...\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   ...\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]]\n",
      "\n",
      "  [[ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   ...\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]]\n",
      "\n",
      "  [[ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   ...\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]]]], shape=(1, 224, 224, 3), dtype=float32)\n",
      "[[9.7417978e-07 4.3291230e-12 9.9999905e-01 1.6998096e-12 2.7025598e-10\n",
      "  4.2674200e-10 1.8054423e-12]]\n",
      "2\n",
      "2\n",
      "tf.Tensor(\n",
      "[[[[-0.08468235 -0.07749961 -0.07131882]\n",
      "   [-0.18272157 -0.17161725 -0.16543648]\n",
      "   [-0.1160549  -0.10887216 -0.10269137]\n",
      "   ...\n",
      "   [-0.25723138 -0.2931859  -0.38896587]\n",
      "   [-0.25723138 -0.2931859  -0.38896587]\n",
      "   [-0.26115295 -0.29710746 -0.39288744]]\n",
      "\n",
      "  [[-0.12781961 -0.12063687 -0.11445608]\n",
      "   [-0.1788     -0.17161725 -0.16543648]\n",
      "   [-0.09252549 -0.08534274 -0.07916196]\n",
      "   ...\n",
      "   [-0.25723138 -0.2931859  -0.38896587]\n",
      "   [-0.25723138 -0.2931859  -0.38896587]\n",
      "   [-0.26115295 -0.29710746 -0.39288744]]\n",
      "\n",
      "  [[-0.14350589 -0.13632314 -0.13014235]\n",
      "   [-0.1160549  -0.10887216 -0.10269137]\n",
      "   [-0.06507451 -0.05789176 -0.05171098]\n",
      "   ...\n",
      "   [-0.25723138 -0.2931859  -0.38896587]\n",
      "   [-0.25723138 -0.2931859  -0.38896587]\n",
      "   [-0.26115295 -0.29710746 -0.39288744]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   ...\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]]\n",
      "\n",
      "  [[ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   ...\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]]\n",
      "\n",
      "  [[ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   ...\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]\n",
      "   [ 0.63296473  0.58916706  0.49338707]]]], shape=(1, 224, 224, 3), dtype=float32)\n",
      "[[1.0494675e-06 9.1856057e-11 1.8543794e-10 9.9999571e-01 3.2182227e-06\n",
      "  6.3030319e-09 7.0712298e-09]]\n",
      "3\n",
      "3\n",
      "tf.Tensor(\n",
      "[[[[-0.21801569 -0.2539702  -0.3105345 ]\n",
      "   [-0.1788     -0.20691137 -0.26739725]\n",
      "   [-0.22585882 -0.25004864 -0.30661294]\n",
      "   ...\n",
      "   [ 0.19374903  0.18916705  0.17966157]\n",
      "   [ 0.17806275  0.17348078  0.15613216]\n",
      "   [ 0.13492548  0.1460298   0.14044589]]\n",
      "\n",
      "  [[-0.1670353  -0.2029898  -0.25955412]\n",
      "   [-0.20232941 -0.22651921 -0.2870051 ]\n",
      "   [-0.22193725 -0.24612705 -0.30661294]\n",
      "   ...\n",
      "   [ 0.16629803  0.16563764  0.1522106 ]\n",
      "   [ 0.14669019  0.1460298   0.12868118]\n",
      "   [ 0.11139608  0.11465725  0.1129949 ]]\n",
      "\n",
      "  [[-0.13566275 -0.17161725 -0.22818157]\n",
      "   [-0.22585882 -0.2539702  -0.31445608]\n",
      "   [-0.1788     -0.2029898  -0.25955412]\n",
      "   ...\n",
      "   [ 0.11139608  0.11465725  0.09730863]\n",
      "   [ 0.09178823  0.09504941  0.07377922]\n",
      "   [ 0.04865098  0.05583373  0.04632824]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.06433725 -0.1167153   0.14828902]\n",
      "   [ 0.05649412 -0.13240157  0.14828902]\n",
      "   [ 0.10747451 -0.08926431  0.20711255]\n",
      "   ...\n",
      "   [ 0.00943529  0.02838274  0.07377922]\n",
      "   [ 0.00159216  0.02838274  0.06985765]\n",
      "   [ 0.01727843  0.02838274  0.07377922]]\n",
      "\n",
      "  [[ 0.34276864  0.17348078  0.41887724]\n",
      "   [ 0.35061178  0.18132392  0.43456352]\n",
      "   [ 0.25257254  0.07544157  0.34436744]\n",
      "   ...\n",
      "   [-0.00232941  0.02838274  0.06985765]\n",
      "   [ 0.00159216  0.03230431  0.06985765]\n",
      "   [ 0.01727843  0.03230431  0.06593608]]\n",
      "\n",
      "  [[ 0.11531765 -0.02651922  0.21103412]\n",
      "   [ 0.10355294 -0.04220549  0.20319098]\n",
      "   [ 0.07218039 -0.07749961  0.18358314]\n",
      "   ...\n",
      "   [-0.00232941  0.02446118  0.07377922]\n",
      "   [ 0.00159216  0.02838274  0.07377922]\n",
      "   [ 0.00551373  0.02838274  0.05809294]]]], shape=(1, 224, 224, 3), dtype=float32)\n",
      "[[2.1225151e-03 9.7084314e-01 2.7034299e-02 3.7997838e-11 9.2307091e-12\n",
      "  2.0879727e-10 2.9118425e-09]]\n",
      "1\n",
      "1\n",
      "tf.Tensor(\n",
      "[[[[-0.29644707 -0.34416628 -0.40465215]\n",
      "   [-0.2925255  -0.33632314 -0.396809  ]\n",
      "   [-0.2807608  -0.32848    -0.3850443 ]\n",
      "   ...\n",
      "   [ 0.13884705  0.13818666 -0.0870051 ]\n",
      "   [ 0.13492548  0.1342651  -0.09092667]\n",
      "   [ 0.13492548  0.1342651  -0.09092667]]\n",
      "\n",
      "  [[-0.2925255  -0.3402447  -0.40073058]\n",
      "   [-0.28860393 -0.33632314 -0.39288744]\n",
      "   [-0.27683923 -0.32455844 -0.38112274]\n",
      "   ...\n",
      "   [ 0.13884705  0.13818666 -0.0870051 ]\n",
      "   [ 0.13492548  0.1342651  -0.09092667]\n",
      "   [ 0.13492548  0.1342651  -0.09092667]]\n",
      "\n",
      "  [[-0.28860393 -0.33632314 -0.40073058]\n",
      "   [-0.28468236 -0.33240157 -0.396809  ]\n",
      "   [-0.27683923 -0.32455844 -0.3850443 ]\n",
      "   ...\n",
      "   [ 0.13884705  0.1342651  -0.0870051 ]\n",
      "   [ 0.13492548  0.1342651  -0.0870051 ]\n",
      "   [ 0.13492548  0.1342651  -0.09092667]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.5310039   0.42838275  0.25809294]\n",
      "   [ 0.55453336  0.45583373  0.28162235]\n",
      "   [ 0.59374905  0.49504942  0.32083803]\n",
      "   ...\n",
      "   [ 0.11923922  0.05191216 -0.16543648]\n",
      "   [ 0.11923922  0.05191216 -0.16543648]\n",
      "   [ 0.11923922  0.05191216 -0.16151491]]\n",
      "\n",
      "  [[ 0.51139605  0.42053962  0.25417137]\n",
      "   [ 0.5466902   0.45583373  0.2894655 ]\n",
      "   [ 0.5976706   0.5068141   0.34044588]\n",
      "   ...\n",
      "   [ 0.11139608  0.04406902 -0.1497502 ]\n",
      "   [ 0.11139608  0.04406902 -0.14582863]\n",
      "   [ 0.11139608  0.04406902 -0.14582863]]\n",
      "\n",
      "  [[ 0.5035529   0.42053962  0.25809294]\n",
      "   [ 0.538847    0.45583373  0.29338706]\n",
      "   [ 0.5976706   0.51465726  0.35221058]\n",
      "   ...\n",
      "   [ 0.09963137  0.03230431 -0.13798548]\n",
      "   [ 0.09963137  0.03622588 -0.13406391]\n",
      "   [ 0.10355294  0.03622588 -0.13406391]]]], shape=(1, 224, 224, 3), dtype=float32)\n",
      "[[4.2242704e-05 5.6206895e-06 2.6687983e-11 9.9995208e-01 2.1751748e-11\n",
      "  3.9904307e-08 1.7674967e-08]]\n",
      "3\n",
      "3\n",
      "tf.Tensor(\n",
      "[[[[-0.28860393 -0.33240157 -0.42818156]\n",
      "   [-0.28468236 -0.32848    -0.42426   ]\n",
      "   [-0.2807608  -0.32455844 -0.42033842]\n",
      "   ...\n",
      "   [ 0.20551373  0.16171607  0.06593608]\n",
      "   [ 0.19374903  0.14995137  0.05417137]\n",
      "   [ 0.2212      0.17740235  0.08162235]]\n",
      "\n",
      "  [[-0.28860393 -0.33240157 -0.42818156]\n",
      "   [-0.28860393 -0.33240157 -0.42818156]\n",
      "   [-0.2807608  -0.32455844 -0.42033842]\n",
      "   ...\n",
      "   [ 0.24865098  0.20485333  0.10907333]\n",
      "   [ 0.21335687  0.16955921  0.07377922]\n",
      "   [ 0.15453333  0.11073568  0.01495569]]\n",
      "\n",
      "  [[-0.28860393 -0.33240157 -0.42818156]\n",
      "   [-0.27683923 -0.32063687 -0.41641685]\n",
      "   [-0.2689961  -0.31279373 -0.40857372]\n",
      "   ...\n",
      "   [ 0.25257254  0.20877491  0.1129949 ]\n",
      "   [ 0.2682588   0.22446118  0.12868118]\n",
      "   [ 0.21727844  0.17348078  0.07770079]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.20625098 -0.25004864 -0.34582862]\n",
      "   [-0.15134902 -0.19514666 -0.29092667]\n",
      "   [-0.10821176 -0.15200941 -0.24778941]\n",
      "   ...\n",
      "   [-0.05723137 -0.10102902 -0.19680902]\n",
      "   [-0.06899608 -0.11279373 -0.20857373]\n",
      "   [-0.08860392 -0.13240157 -0.22818157]]\n",
      "\n",
      "  [[-0.11213333 -0.15593098 -0.25171098]\n",
      "   [-0.12389804 -0.16769569 -0.2634757 ]\n",
      "   [-0.09252549 -0.13632314 -0.23210314]\n",
      "   ...\n",
      "   [-0.08468235 -0.12848    -0.22426   ]\n",
      "   [-0.11997647 -0.16377412 -0.25955412]\n",
      "   [-0.07683922 -0.12063687 -0.21641687]]\n",
      "\n",
      "  [[-0.1160549  -0.15985255 -0.25563255]\n",
      "   [-0.15527059 -0.19906823 -0.29484823]\n",
      "   [-0.13174118 -0.17553882 -0.27131882]\n",
      "   ...\n",
      "   [-0.1670353  -0.21083294 -0.30661294]\n",
      "   [-0.11213333 -0.15593098 -0.25171098]\n",
      "   [-0.03370196 -0.07749961 -0.17327961]]]], shape=(1, 224, 224, 3), dtype=float32)\n",
      "[[2.3498503e-10 5.7877947e-10 1.0000000e+00 1.6076069e-15 5.7463964e-12\n",
      "  3.8938224e-13 1.2919259e-15]]\n",
      "2\n",
      "2\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Load the model into interpreters\n",
    "interpreter_qat = tf.lite.Interpreter(model_path=\"vggRaf.tflite\")\n",
    "interpreter_qat.allocate_tensors()\n",
    "\n",
    "# Evaluate the performance\n",
    "print(evaluate_model(interpreter_qat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8764264753831106\n"
     ]
    }
   ],
   "source": [
    "# Load the model into interpreters\n",
    "interpreter_qat = tf.lite.Interpreter(model_path=\"senetRight.tflite\")\n",
    "interpreter_qat.allocate_tensors()\n",
    "\n",
    "# Evaluate the performance\n",
    "print(evaluate_model(interpreter_qat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = tf.cast(X_train, tf.float32)\n",
    "emotion_ds = tf.data.Dataset.from_tensor_slices((images)).batch(1)\n",
    "\n",
    "def representative_data_gen():\n",
    "  for input_value in emotion_ds.take(3500):\n",
    "    yield [input_value]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
